{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PacktPublishing/Modern-Computer-Vision-with-PyTorch-2E/blob/main/Chapter18/convert_to_onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggtWhvNjlWfO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try:\n",
        "  from torch_snippets import *\n",
        "except:\n",
        "  %pip install torch-snippets gitPython lovely-tensors\n",
        "  from torch_snippets import *\n",
        "\n",
        "from git import Repo\n",
        "\n",
        "repository_url = 'https://github.com/sizhky/quantization'\n",
        "destination_directory = '/content/quantization'\n",
        "if exists(destination_directory):\n",
        "  repo = Repo(destination_directory)\n",
        "else:\n",
        "  repo = Repo.clone_from(repository_url, destination_directory)\n",
        "\n",
        "%cd {destination_directory}\n",
        "%pip install -qq -r requirements.txt # this will take about 5 min of time\n",
        "%pip install onnxruntime-gpu onnx\n",
        "# print(repo.git.pull('origin', 'main'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "g4_DGZ9Pz7ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to `Debug=false` in the line below\n",
        "# to train on a larger dataset\n",
        "%env DEBUG=true\n",
        "!make train"
      ],
      "metadata": {
        "id": "6vmhVRnHoExo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cbfd0d-22e9-4ae3-f5f5-3c309cf73c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: DEBUG=true\n",
            "python -m src.defect_classification.train\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100% 528M/528M [00:07<00:00, 78.3MB/s]\n",
            "Downloading readme: 100% 495/495 [00:00<00:00, 2.57MB/s]\n",
            "Downloading data: 100% 306M/306M [00:07<00:00, 38.9MB/s]\n",
            "Downloading data: 100% 305M/305M [00:06<00:00, 46.0MB/s]\n",
            "Downloading data: 100% 263M/263M [00:06<00:00, 41.7MB/s]\n",
            "Generating train split: 100% 2331/2331 [00:02<00:00, 1049.98 examples/s]\n",
            "Generating valid split: 100% 1004/1004 [00:01<00:00, 884.39 examples/s]\n",
            "Class Balance\n",
            " \n",
            "```↯ AttrDict ↯\n",
            "train\n",
            "  non_defect - 50 (int)\n",
            "  defect - 50 (int)\n",
            "valid\n",
            "  non_defect - 50 (int)\n",
            "  defect - 50 (int)\n",
            "\n",
            "```\n",
            "\n",
            "Map: 100% 100/100 [00:19<00:00,  5.22 examples/s]\n",
            "Map: 100% 100/100 [00:19<00:00,  5.03 examples/s]\n",
            "Epoch: 1 train_epoch_loss=0.689\n",
            "Epoch: 11 train_epoch_loss=0.592\n",
            "Epoch: 21 train_epoch_loss=0.478\n",
            "Saved model to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarks"
      ],
      "metadata": {
        "id": "bQAvk8xYz8kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.path.append('src')\n",
        "from defect_classification.model import SDD\n",
        "from defect_classification.train import process_example, DefectsDataset\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "UoGQDq__ocy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = load_dataset('sizhkhy/kolektor_sdd2', split=\"valid[:50]+valid[-50:]\")\n",
        "val_ds = val_ds.map(process_example).remove_columns(['split', 'path'])\n",
        "val_ds.set_format(\"pt\", columns=[\"image\", \"label\"], output_all_columns=True)\n",
        "val_ds = DefectsDataset(val_ds)\n",
        "val_dl = DataLoader(val_ds, batch_size=32, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "JL_SiDXrgexO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "model = torch.load('model.pth').to(device)"
      ],
      "metadata": {
        "id": "YIl8GQHsjfE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: export to onnx with dynamic axes\n",
        "model.eval()\n",
        "i, _ = next(iter(val_dl))\n",
        "with torch.no_grad():\n",
        "    # first prediction is model warmup\n",
        "    model(i.to(device))\n",
        "    print(f'Time taken by pytorch model on sample input')\n",
        "    %time pred_pytorch_model = model(i.to(device))\n",
        "    pred_pytorch_model = pred_pytorch_model.to(device).numpy().reshape(-1)\n"
      ],
      "metadata": {
        "id": "KFQHAu0Aik46",
        "outputId": "ddf36f30-b174-4256-a437-ba8279547acd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken by pytorch model on sample input\n",
            "CPU times: user 15.2 s, sys: 2.81 s, total: 18 s\n",
            "Wall time: 18 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_names = ['image']\n",
        "output_names = ['label']\n",
        "dynamic_axes = {'image': {0: 'batch_size'}, 'label': {0: 'batch_size'}}\n",
        "onnx_file_path = 'sdd_base.onnx'\n",
        "with open(onnx_file_path, 'wb') as f:\n",
        "    torch.onnx.export(\n",
        "        model,\n",
        "        i[:1].to(device),\n",
        "        f,\n",
        "        export_params=True,\n",
        "        verbose=False,\n",
        "        opset_version=13,\n",
        "        do_constant_folding=True,\n",
        "        input_names=input_names,\n",
        "        output_names=output_names,\n",
        "        dynamic_axes=dynamic_axes\n",
        "    )\n"
      ],
      "metadata": {
        "id": "yGnodrRlhmWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime import InferenceSession\n",
        "# load the onnx model on gpu\n",
        "session = InferenceSession('sdd_base.onnx', providers=['CPUExecutionProvider'])\n",
        "# make sample prediction\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_name = session.get_outputs()[0].name\n",
        "\n",
        "input = i.numpy()\n",
        "\n",
        "# first prediction is model warmup\n",
        "pred_onnx = session.run(None, {input_name: input})[0]\n",
        "print(f'Time taken by ONNX model on same input')\n",
        "%time pred_onnx = session.run(None, {input_name: input})\n",
        "pred____onnx_model = pred_onnx[0].reshape(-1)"
      ],
      "metadata": {
        "id": "MAgpUVW2iyKE",
        "outputId": "e9f44077-a7e8-4260-8a77-c6535a9afbb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken by ONNX model on same input\n",
            "CPU times: user 13.7 s, sys: 468 ms, total: 14.1 s\n",
            "Wall time: 15.3 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Both the pytorch and onnx model\\'s predictions are identical - ')\n",
        "np.allclose(\n",
        "    pred_pytorch_model,\n",
        "    pred____onnx_model,\n",
        ")"
      ],
      "metadata": {
        "id": "u4yHYb6boE5t",
        "outputId": "1aebc4c3-26a5-4c50-b074-da167f1cd8f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Both the pytorch and onnx model's predictions are identical - \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_O5VinDMpaXy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}